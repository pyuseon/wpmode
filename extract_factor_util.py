from selenium.webdriver.common.by import By


def find_elements_intelligently(driver, base_element=None):
    """ì§€ëŠ¥ì ìœ¼ë¡œ ë‰´ìŠ¤ ìš”ì†Œë“¤ì„ ì°¾ëŠ” í•¨ìˆ˜"""
    search_base = base_element if base_element else driver

    # 1ë‹¨ê³„: ë‰´ìŠ¤ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ê¸° ìœ„í•œ íŒ¨í„´ë“¤
    container_patterns = [
        # ìµœì‹  ì»¨í…Œì´ë„ˆ íŒ¨í„´ë“¤
        "div.sds-comps-vertical-layout.sds-comps-full-layout.fender-news-item-list-tab"
        "div.fender-news-item-list-tab",
        "div[class*='fender-news-item-list']",
    ]

    container = None
    for pattern in container_patterns:
        try:
            found_container = search_base.find_element(By.CSS_SELECTOR, pattern)
            if found_container:
                container = found_container
                print(f"ğŸ¯ ë‰´ìŠ¤ ì»¨í…Œì´ë„ˆ ë°œê²¬: {pattern}")
                break
        except:
            continue

    if not container:
        print("âŒ ë‰´ìŠ¤ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return []

    # 2ë‹¨ê³„: ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ ê°œë³„ ë‰´ìŠ¤ ì¹´ë“œë“¤ ì°¾ê¸°
    card_patterns = [
        # ì •í™•í•œ ê°œë³„ ì¹´ë“œ íŒ¨í„´ (2024ë…„ 6ì›”)
         # ì •í™•í•œ ê°œë³„ ì¹´ë“œ íŒ¨í„´ (2024ë…„ 6ì›”)
        "div.sds-comps-vertical-layout.sds-comps-full-layout._4zQ0QZWfn7bqZ_ul5OV",
        "div[class*='sds-comps-vertical-layout'][class*='sds-comps-full-layout'][class*='_4zQ0QZWfn7bqZ_ul5OV']",
        "div[class*='_4zQ0QZWfn7bqZ_ul5OV']",  # ê³ ìœ  í´ë˜ìŠ¤ë¡œ ì°¾ê¸°
    ]

    found_cards = []
    for pattern in card_patterns:
        try:
            elements = container.find_elements(By.CSS_SELECTOR, pattern)
            if elements and len(elements) > 1:  # ì—¬ëŸ¬ ê°œì˜ ì¹´ë“œê°€ ìˆì–´ì•¼ í•¨
                print(f"ğŸ¯ ê°œë³„ ë‰´ìŠ¤ ì¹´ë“œ íŒ¨í„´ '{pattern}'ë¡œ {len(elements)}ê°œ ë°œê²¬")
                found_cards = elements
                break
            elif elements and len(elements) == 1:
                print(f"âš ï¸ íŒ¨í„´ '{pattern}'ë¡œ 1ê°œë§Œ ë°œê²¬ - ë‹¤ìŒ íŒ¨í„´ ì‹œë„")
        except Exception as e:
            print(f"âŒ íŒ¨í„´ '{pattern}' ì‹œë„ ì‹¤íŒ¨: {e}")
            continue

    # 3ë‹¨ê³„: ì—¬ì „íˆ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ë” í¬ê´„ì ìœ¼ë¡œ ì°¾ê¸°
    if not found_cards:
        print("ğŸ” í¬ê´„ì  ê²€ìƒ‰ ì‹œì‘...")
        try:
            # ì»¨í…Œì´ë„ˆì˜ ëª¨ë“  ì§ì ‘ ìì‹ë“¤ ì¤‘ì—ì„œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²ƒë“¤ ì°¾ê¸°
            all_children = container.find_elements(By.XPATH, "./*")
            potential_cards = []

            for child in all_children:
                # í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ì¶©ë¶„í•˜ê³  ë§í¬ê°€ ìˆëŠ” ìš”ì†Œë“¤ë§Œ ì„ íƒ
                if child.text.strip() and len(child.text.strip()) > 10:
                    links = child.find_elements(By.CSS_SELECTOR, "a")
                    if links:  # ë§í¬ê°€ ìˆìœ¼ë©´ ë‰´ìŠ¤ ì¹´ë“œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                        potential_cards.append(child)

            if potential_cards:
                print(f"ğŸ¯ í¬ê´„ì  ê²€ìƒ‰ìœ¼ë¡œ {len(potential_cards)}ê°œ ì¹´ë“œ ë°œê²¬")
                found_cards = potential_cards
        except Exception as e:
            print(f"âŒ í¬ê´„ì  ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return found_cards




def extract_title_intelligently(card):
    """ì§€ëŠ¥ì ìœ¼ë¡œ ì œëª©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    title_patterns = [
        # ì •í™•í•œ ìµœì‹  íŒ¨í„´ (2024ë…„ 6ì›”)
        "span.sds-comps-text.sds-comps-text-ellipsis.sds-comps-text-ellipsis-1.sds-comps-text-type-headline1",
        "span[class*='sds-comps-text-type-headline1']",
        "span[class*='sds-comps-text'][class*='headline1']",
    ]

    for pattern in title_patterns:
        try:
            elements = card.find_elements(By.CSS_SELECTOR, pattern)
            for element in elements:
                text = element.text.strip()
                if text and len(text) > 5:  # ìµœì†Œ 5ê¸€ì ì´ìƒ
                    print(f"    ğŸ“° ì œëª© ë°œê²¬ (íŒ¨í„´: {pattern}): {text[:50]}...")
                    return text
        except:
            continue

    return ""

def extract_naver_url(card):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ URLì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        naver_container = card.find_element(By.CSS_SELECTOR, ".sds-comps-profile-info")
        naver_link = naver_container.find_element(By.CSS_SELECTOR, "a[href*='n.news.naver']")
        return naver_link.get_attribute("href")
    except:
        return ""

def extract_original_url(card):
    """ì›ë³¸ ë‰´ìŠ¤ URLì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        headline_span = card.find_element(By.CSS_SELECTOR,
                                        "span.sds-comps-text.sds-comps-text-ellipsis.sds-comps-text-ellipsis-1.sds-comps-text-type-headline1")
        original_link = headline_span.find_element(By.XPATH, "..")  # ë¶€ëª¨ a íƒœê·¸

        # a íƒœê·¸ì´ê³  nocr="1" ì†ì„±ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
        if (original_link.tag_name.lower() == 'a' and
                original_link.get_attribute("nocr") == "1"):
            href = original_link.get_attribute("href")
            if href and "media.naver.com" not in href:
                return href
    except:
        pass
    return ""


def extract_press(card):
    press = ""
    press_patterns = [
        # ì£¼ì–´ì§„ êµ¬ì¡°ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì…€ë ‰í„°
        "div.sds-comps-horizontal-layout.sds-comps-inline-layout.sds-comps-profile-info span.sds-comps-text.sds-comps-text-ellipsis.sds-comps-text-ellipsis-1.sds-comps-text-type-body2.sds-comps-text-weight-sm",

        # ì¢€ ë” ê°„ë‹¨í•œ ë²„ì „ë“¤ (ë°±ì—…ìš©)
        ".sds-comps-profile-info span.sds-comps-text-ellipsis",
        ".sds-comps-profile-info .sds-comps-text-type-body2",
        "div[class*='profile-info'] span[class*='text-ellipsis']",
    ]

    for pattern in press_patterns:
        try:
            press_elem = card.find_element(By.CSS_SELECTOR, pattern)
            press = press_elem.text.strip()
            if press:
                break
        except:
            continue

    return press

def extract_published(card):
    published = ""
    date_patterns = [
        # ì •í™•í•œ êµ¬ì¡° íŒ¨í„´
        ".sds-comps-horizontal-layout.sds-comps-inline-layout.sds-comps-profile-info span.sds-comps-text.sds-comps-text-type-body2.sds-comps-text-weight-sm",
        ".sds-comps-profile-info span.sds-comps-text-type-body2.sds-comps-text-weight-sm",
        ".sds-comps-profile-info span.sds-comps-text-type-body2",
        ".sds-comps-profile-info span[class*='sds-comps-text-weight-sm']",
    ]
    for pattern in date_patterns:
        try:
            date_elems = card.find_elements(By.CSS_SELECTOR, pattern)
            for date_elem in date_elems:
                text = date_elem.text.strip()
                # 2024.06.15 í˜•ì‹ ë˜ëŠ” ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ í™•ì¸
                import re
                if text and (
                        # YYYY.MM.DD í˜•ì‹
                        re.match(r'\d{4}\.\d{1,2}\.\d{1,2}', text)
                ):
                    if len(text) < 50:  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸
                        published = text
                        print(f"        ğŸ“… ë°œí–‰ì¼ ë°œê²¬ (íŒ¨í„´: {pattern}): {text}")
                        break
            if published:
                break
        except:
            continue
    return published



def extract_img_url(card):
    image_url = ""
    image_patterns = [
        ".sds-comps-base-layout .sds-comps-inline-layout .sds-comps-image img",
        ".sds-rego-thumb-overlay img",
        ".fit-contain img",
        ".forced-ratio img",
        "img"
    ]
    for pattern in image_patterns:
        try:
            img_elem = card.find_element(By.CSS_SELECTOR, pattern)
            src = img_elem.get_attribute('src')
            if src and src.startswith('http'):
                image_url = src
                break
            # data-srcë‚˜ ë‹¤ë¥¸ ì†ì„±ë„ í™•ì¸
            data_src = img_elem.get_attribute('data-src')
            if data_src and data_src.startswith('http'):
                image_url = data_src
                break
        except:
            continue
    return image_url

